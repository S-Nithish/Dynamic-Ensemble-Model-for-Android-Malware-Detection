# Dynamic-Ensemble-Model-for-Android-Malware-Detection
Composition and Adaptation of Ensemble Model for Android Malware Detection

# Key Components
## Data Preparation

* **Dataset:** AndMal2020, a collection of Android malware labels and features.
* **Label Encoding:** Categorical variables are encoded using LabelEncoder from sklearn.preprocessing.
* **Standardization:** Numerical features are standardized using StandardScaler from sklearn.preprocessing.
* **Feature Elimination:** Relevant features are selected, and irrelevant ones are removed using methods from pandas.
  
## Model Training

**Base Learners:**
* RandomForestClassifier
* SVC (Support Vector Classifier)
* MLPClassifier (Multi-layer Perceptron)
* XGBClassifier
* LGBMClassifier 
* KNeighborsClassifier
  
**Meta Learner:**
* A RandomForestClassifier from sklearn.ensemble is used as the meta-learner, trained on the predictions of the base learners.
  
## Model Evaluation

* **Confusion Matrix:**The confusion matrix is computed for the ensemble model using confusion_matrix from sklearn.metrics.
* **Performance Comparison:** The performance of the ensemble model is compared to individual base learners using various metrics from sklearn.metrics.
  
## Model Interpretation with LIME

**LIME Explainer:** LIME (Local Interpretable Model-agnostic Explanations) is used to interpret the predictions of the ensemble model, using the lime library.
**Explanation Visualization:** Feature contributions to predictions are visualized using bar plots with matplotlib.pyplot.

## Implementation Details

## Libraries Used:

* numpy: Numerical operations
* pandas: Data manipulation and analysis
* sklearn.preprocessing: Label encoding and feature standardization
* sklearn.model_selection: Train/test splitting
* sklearn.ensemble: Ensemble methods for base and meta learners
* sklearn.svm: Support Vector Classifier
* sklearn.neural_network: Multi-layer Perceptron Classifier
* xgboost: XGBoost classifier
* lightgbm: LightGBM classifier
* sklearn.neighbors: K-Nearest Neighbors classifier
* sklearn.metrics: Performance metrics
* lime: Model interpretation
* matplotlib.pyplot: Visualization
* seaborn: Visualization
  
## Code Structure: The notebook consists of sequential code cells for:

* Data preprocessing: Label encoding and standardization
* Dataset splitting: Train/test split
* Feature selection: Selecting relevant features
* Model training: Training multiple base learners and a meta-learner
* Model evaluation: Computing confusion matrix and comparing performance
* Model interpretation: Using LIME to interpret and visualize feature contributions
